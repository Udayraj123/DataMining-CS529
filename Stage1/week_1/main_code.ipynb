{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "subSize=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDegrees(G):\n",
    "    # sum of in and out degrees by default. use in_degree for specific\n",
    "    return list(nx.degree(G))\n",
    "\n",
    "def compareDirect(a,b,size=10,write=\"\"):        \n",
    "    print(\"Calculated :\\t\",a[:size],\"...\")\n",
    "    print(\"\")\n",
    "    print(\"Expected :\\t\",b[:size],\"...\")    \n",
    "    print(\"\")\n",
    "#     diffs=[ abs(a-b) for a,b in zip(a,b)]\n",
    "#     print(\"Absolute Diffs: \",diffs[:size],\"...\" if size<len(a) else \"\")\n",
    "#     print(\"\")\n",
    "#     print(\"Sum of absolute diffs: \",sum(diffs))\n",
    "#     ratios=[ a/b if b else '0' for a,b in zip(a,b)]\n",
    "#     print(\"Ratios: \",ratios)\n",
    "    if(write!=\"\"):\n",
    "        a=sorted(a,reverse=True)\n",
    "        b=sorted(b,reverse=True)\n",
    "        pd.DataFrame(a).to_csv(write+\"_code.csv\",header=False,index=None)\n",
    "        pd.DataFrame(b).to_csv(write+\"_tool.csv\",header=False,index=None)\n",
    "        \n",
    "    print(\"\\n Spearman rank correlation: \")\n",
    "    print(stats.spearmanr(a,b))\n",
    "    \n",
    "    \n",
    "    \n",
    "def compare(a,b,name,size=10):\n",
    "    a=sorted(a,key=lambda x:x[1],reverse=True)\n",
    "    b=sorted(b,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    pd.DataFrame(a).to_csv(name+\"_code.csv\",header=False,index=None)\n",
    "    pd.DataFrame(b).to_csv(name+\"_tool.csv\",header=False,index=None)\n",
    "    \n",
    "    a=[x[1] for x in a]\n",
    "    b=[x[1] for x in b]\n",
    "    compareDirect(a,b,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally: 116408 nodes\n",
      "Taken: 10000 random nodes from 10000 highest degree nodes\n"
     ]
    }
   ],
   "source": [
    "diG=nx.read_weighted_edgelist(\"higgs-mention_network.edgelist\",create_using=nx.DiGraph())#read_edgelist(\"com-dblp.ungraph.txt\")\n",
    "N=diG.number_of_nodes()\n",
    "print(\"Originally: \"+str(N)+\" nodes\")\n",
    "\n",
    "degrees=sorted(getDegrees(diG),key=lambda x:x[1])\n",
    "subG=diG.subgraph([x[0] for x in degrees[N-subSize:]])\n",
    "# subG=diG.subgraph(np.random.choice(list(subG.nodes),size=subSize, replace=False))\n",
    "subGdegrees=getDegrees(subG)\n",
    "subN=subG.number_of_nodes()\n",
    "print(\"Taken: \"+str(subN)+\" random nodes from \"+str(subSize)+\" highest degree nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=subG\n",
    "if(subN<200):    \n",
    "    pos=dict.fromkeys(G)\n",
    "    for d in pos:\n",
    "        pos[d]=(int(20*np.random.rand()),int(20*np.random.rand())) if d!='3998' else (0,0)\n",
    "    nx.draw_networkx(G,pos)\n",
    "    labels = nx.get_edge_attributes(G,'weight')\n",
    "#     nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated :\t [0.2075207520752075, 0.0613061306130613, 0.06050605060506051, 0.045404540454045406, 0.038303830383038306, 0.0338033803380338, 0.0319031903190319, 0.022602260226022602, 0.021602160216021602, 0.020602060206020602] ...\n",
      "\n",
      "Expected :\t [0.20752075207520754, 0.06130613061306131, 0.06050605060506051, 0.045404540454045406, 0.038303830383038306, 0.0338033803380338, 0.0319031903190319, 0.022602260226022602, 0.021602160216021602, 0.020602060206020602] ...\n",
      "\n",
      "\n",
      " Spearman rank correlation: \n",
      "SpearmanrResult(correlation=0.9999999999999999, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Degree Centrality = degree(n) = In undirected graph it is no of edges \n",
    "\"\"\"\n",
    "subNminus=subN-1\n",
    "degreeCentrality=[(x[0],x[1]/subNminus) for x in subGdegrees]\n",
    "compare(degreeCentrality,list(nx.degree_centrality(subG).items()),name=\"degree_centrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pairs shortest path lengths\n",
    "all_spls=nx.floyd_warshall(subG) #floyd_warshall gives inf too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated :\t [0.16859957600698341, 0.15972591411187903, 0.15007215007215008, 0.14078933666562535, 0.1344956413449564, 0.11722373954133612, 0.10268094478620794, 0.09685507557847983, 0.09651283149516367, 0.09583554846712743] ...\n",
      "\n",
      "Expected :\t [0.16859957600698341, 0.15972591411187903, 0.15007215007215008, 0.14078933666562535, 0.1344956413449564, 0.11722373954133612, 0.10268094478620794, 0.09685507557847983, 0.09651283149516367, 0.09583554846712743] ...\n",
      "\n",
      "\n",
      " Spearman rank correlation: \n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Closeness centrality -  is the average length of the shortest path between the node and all other nodes in the graph i.e.\n",
    "in the connected part of graph containing the node. If the graph is not completely connected, \n",
    "this algorithm computes the closeness centrality for each connected part separately.\n",
    ">> Normalized again with a factor n-1/N-1\n",
    "\"\"\"\n",
    "\n",
    "closeness=[]\n",
    "for n,lengths in all_spls.items():\n",
    "    component=[x for x in lengths.values()  if x!=np.inf ]\n",
    "    sumDists=sum(component)\n",
    "    lminus=len(component)-1\n",
    "    n_fac=lminus/subNminus\n",
    "    closeness.append( (n,(lminus / sumDists * n_fac) if(sumDists!=0) else 0.0) )\n",
    "    \n",
    "#From the tool\n",
    "ideal=nx.closeness_centrality(subG,distance='weight') #consider the weights\n",
    "\n",
    "compare(closeness,list(ideal.items()),name=\"closeness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated :\t [1429.411904761905, 1336.4452380952382, 775.2595238095241, 738.7928571428573, 727.4785714285714, 506.3333333333333, 356.0, 295.0, 175.1547619047619, 164.82142857142858] ...\n",
      "\n",
      "Expected :\t [1429.411904761905, 1336.4452380952382, 775.2595238095241, 738.7928571428573, 727.4785714285714, 506.3333333333333, 356.0, 295.0, 175.1547619047619, 164.82142857142858] ...\n",
      "\n",
      "\n",
      " Spearman rank correlation: \n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Betweenness centrality computed as follows:\n",
    "1. For each pair of vertices (s,t), compute the shortest paths between them. <-- spaths\n",
    "2. For each pair of vertices (s,t), determine the fraction which pass through the vertex v. <-- iterating on paths\n",
    "3. Sum this fraction over all pairs of vertices (s,t). <-- sum while iterating\n",
    "\n",
    "Betweenness(v) = no of SPs passing thru v/Total no of SPs\n",
    "\"\"\"\n",
    "from itertools import count\n",
    "from heapq import heappush, heappop\n",
    "\n",
    "def accumulate_from_S(betweenness, S, P, sigma, s):\n",
    "    delta = dict.fromkeys(S, 0)\n",
    "    while S:\n",
    "        w = S.pop()\n",
    "        coeff = (1.0 + delta[w]) / sigma[w]\n",
    "        for v in P[w]:\n",
    "            delta[v] += sigma[v] * coeff # count paths\n",
    "        if w != s:\n",
    "            betweenness[w] += delta[w]\n",
    "    return betweenness\n",
    "\n",
    "def single_source_dijkstra_multi_sps(G, s, weight='weight'):\n",
    "    S = []\n",
    "    P = {}\n",
    "    for v in G:\n",
    "        P[v] = []\n",
    "    sigma = dict.fromkeys(G, 0.0)    # sigma[v]=0 for v in G\n",
    "    D = {}\n",
    "    sigma[s] = 1.0\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    seen = {s: 0}\n",
    "    c = count()\n",
    "    Q = []   # use Q as heap with (distance,node id) tuples\n",
    "    push(Q, (0, next(c), s, s))\n",
    "    while Q:\n",
    "        (dist, _, pred, v) = pop(Q)\n",
    "        if v in D:\n",
    "            continue  # already searched this node.\n",
    "        sigma[v] += sigma[pred]  # count paths\n",
    "        S.append(v)\n",
    "        D[v] = dist\n",
    "        for w, edgedata in G[v].items():\n",
    "            vw_dist = dist + edgedata.get(weight, 1)\n",
    "            if w not in D and (w not in seen or vw_dist < seen[w]):\n",
    "                seen[w] = vw_dist\n",
    "                push(Q, (vw_dist, next(c), v, w))\n",
    "                sigma[w] = 0.0\n",
    "                P[w] = [v]\n",
    "            \n",
    "            # \"\"\" Multiple paths handled here\"\"\"\n",
    "            elif vw_dist == seen[w]:  # handle equal paths\n",
    "                sigma[w] += sigma[v]\n",
    "                P[w].append(v)\n",
    "                \n",
    "    return S, P, sigma\n",
    "                \n",
    "betweenness = dict.fromkeys(subG, 0.0)  \n",
    "for s in subG:\n",
    "    S, P, sigma = single_source_dijkstra_multi_sps(subG, s, 'weight')\n",
    "    betweenness = accumulate_from_S(betweenness,S,P,sigma,s)\n",
    "\n",
    "compare(list(betweenness.items()),list(nx.betweenness_centrality(subG,normalized=False,weight='weight').items()),name=\"betweenness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G=nx.path_graph(4)\n",
    "# eigenvector_centrailty=power_iteration(G,num_simulations=30)\n",
    "\n",
    "# compareDirect(eigenvector_centrailty,list(nx.eigenvector_centrality(G,weight='weight').values()))#,size=subSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left iters:  3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Eignevector Centrality\n",
    "Concept: connections to high-scoring nodes contribute more to the score of the node in question\n",
    "         than equal connections to low-scoring nodes.\n",
    "The Eigenvector corresponding to largest eigenvalue gives the desired centrality\n",
    "For this we use the power method\n",
    "It is an eigenvalue algorithm: given a diagonalizable matrix A, the algorithm will give greatest(in absolute value) eigenvalue of A,\n",
    "and a nonzero vector v, the corresponding eigenvector. The algorithm is also known as the Von Mises iteration.[1]\n",
    "\n",
    "Power iteration is a very simple algorithm, but it may converge slowly. It is suitable for large sparse matrices\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def power_iteration(G, num_simulations):\n",
    "    A=nx.to_numpy_matrix(G);\n",
    "    A=np.array(A)\n",
    "    EPSILON = np.longdouble(1e-9)\n",
    "    b_k = np.random.rand(A.shape[1])\n",
    "    for _ in range(num_simulations):\n",
    "#     while 1:\n",
    "        # calculate the matrix-by-vector product Ab\n",
    "        b_k1 = np.dot(A, b_k)\n",
    "        # calculate the norm\n",
    "        b_k1_norm = np.linalg.norm(b_k1)        \n",
    "        b_k_next = b_k1 / b_k1_norm\n",
    "        if(np.sum(abs(b_k_next-b_k))<EPSILON):#*len(b_k)\n",
    "            break\n",
    "        b_k=b_k_next\n",
    "        num_simulations-=1;\n",
    "    print(\"left iters: \",num_simulations)\n",
    "    return b_k_next\n",
    "\n",
    "eigenvector_centrality=power_iteration(subG,num_simulations=30)\n",
    "\n",
    "# compare(list(zip(G.nodes,eigenvector_centrality)),list(nx.eigenvector_centrality(subG,weight='weight').items()),name=\"eigenvector\")#,size=subSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84293051e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       5.33102366e-03, 4.01737497e-01, 7.62496634e-03, 1.31617417e-02,\n",
       "       4.31021381e-37, 0.00000000e+00, 3.67327233e-37, 0.00000000e+00,\n",
       "       6.55088767e-02, 5.56330509e-46, 0.00000000e+00, 4.18581705e-27,\n",
       "       5.37941867e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.87550728e-04,\n",
       "       7.70987294e-05, 2.37672127e-03, 1.91912997e-32, 0.00000000e+00,\n",
       "       1.85133947e-03, 1.14805234e-02, 7.06649887e-46, 1.62511388e-04,\n",
       "       4.59259393e-04, 1.60381237e-45, 0.00000000e+00, 3.54012721e-03,\n",
       "       3.50221753e-02, 0.00000000e+00, 0.00000000e+00, 2.94930033e-04,\n",
       "       7.71179373e-02, 1.77846514e-03, 0.00000000e+00, 4.23287786e-46,\n",
       "       1.12124306e-02, 0.00000000e+00, 0.00000000e+00, 1.28204152e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.91313676e-03,\n",
       "       0.00000000e+00, 1.00748261e-01, 0.00000000e+00, 4.50239976e-37,\n",
       "       0.00000000e+00, 2.85398341e-03, 3.27684593e-02, 0.00000000e+00,\n",
       "       1.67763480e-02, 5.16686666e-46, 1.59621082e-02, 2.43698504e-03,\n",
       "       1.82430064e-02, 1.76968483e-03, 6.17823706e-03, 2.58580940e-03,\n",
       "       3.21299970e-27, 1.72313532e-03, 0.00000000e+00, 1.09488839e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.58267876e-02, 7.41961580e-04,\n",
       "       1.50968556e-04, 1.04908160e-37, 1.72313532e-03, 0.00000000e+00,\n",
       "       1.63443971e-45, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.55303572e-45, 2.97739395e-03, 0.00000000e+00, 1.74597820e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.64593898e-45, 8.99111838e-01,\n",
       "       4.88184751e-26, 1.83663617e-37, 0.00000000e+00, 2.53112491e-15,\n",
       "       3.46204418e-04, 0.00000000e+00, 1.61346580e-02, 2.10348791e-03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.9995555837724588, pvalue=2.4708958021469265e-151)\n"
     ]
    }
   ],
   "source": [
    "y=np.array([1.84293051e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       5.33102366e-03, 4.01737497e-01, 7.62496634e-03, 1.31617417e-02,\n",
    "       4.31021381e-37, 0.00000000e+00, 3.67327233e-37, 0.00000000e+00,\n",
    "       6.55088767e-02, 5.56330509e-46, 0.00000000e+00, 4.18581705e-27,\n",
    "       5.37941867e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.87550728e-04,\n",
    "       7.70987294e-05, 2.37672127e-03, 1.91912997e-32, 0.00000000e+00,\n",
    "       1.85133947e-03, 1.14805234e-02, 7.06649887e-46, 1.62511388e-04,\n",
    "       4.59259393e-04, 1.60381237e-45, 0.00000000e+00, 3.54012721e-03,\n",
    "       3.50221753e-02, 0.00000000e+00, 0.00000000e+00, 2.94930033e-04,\n",
    "       7.71179373e-02, 1.77846514e-03, 0.00000000e+00, 4.23287786e-46,\n",
    "       1.12124306e-02, 0.00000000e+00, 0.00000000e+00, 1.28204152e-04,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.91313676e-03,\n",
    "       0.00000000e+00, 1.00748261e-01, 0.00000000e+00, 4.50239976e-37,\n",
    "       0.00000000e+00, 2.85398341e-03, 3.27684593e-02, 0.00000000e+00,\n",
    "       1.67763480e-02, 5.16686666e-46, 1.59621082e-02, 2.43698504e-03,\n",
    "       1.82430064e-02, 1.76968483e-03, 6.17823706e-03, 2.58580940e-03,\n",
    "       3.21299970e-27, 1.72313532e-03, 0.00000000e+00, 1.09488839e-02,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.58267876e-02, 7.41961580e-04,\n",
    "       1.50968556e-04, 1.04908160e-37, 1.72313532e-03, 0.00000000e+00,\n",
    "       1.63443971e-45, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       1.55303572e-45, 2.97739395e-03, 0.00000000e+00, 1.74597820e-02,\n",
    "       0.00000000e+00, 0.00000000e+00, 1.64593898e-45, 8.99111838e-01,\n",
    "       4.88184751e-26, 1.83663617e-37, 0.00000000e+00, 2.53112491e-15,\n",
    "       3.46204418e-04, 0.00000000e+00, 1.61346580e-02, 2.10348791e-03])\n",
    "\n",
    "x=np.array([1.84293050e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       5.33102364e-03, 4.01737494e-01, 7.62496630e-03, 1.31617682e-02,\n",
    "       1.01287748e-30, 0.00000000e+00, 3.54497530e-31, 0.00000000e+00,\n",
    "       6.55088762e-02, 5.00978995e-38, 0.00000000e+00, 2.20268647e-22,\n",
    "       5.37941904e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.87551965e-04,\n",
    "       7.70987289e-05, 2.37672873e-03, 2.24316495e-26, 0.00000000e+00,\n",
    "       1.85133946e-03, 1.14805234e-02, 8.82490582e-38, 1.62511443e-04,\n",
    "       4.59259390e-04, 1.73757348e-37, 0.00000000e+00, 3.54012872e-03,\n",
    "       3.50221769e-02, 0.00000000e+00, 0.00000000e+00, 2.94930031e-04,\n",
    "       7.71179367e-02, 1.77846513e-03, 0.00000000e+00, 1.63533065e-37,\n",
    "       1.12124305e-02, 0.00000000e+00, 0.00000000e+00, 1.28204159e-04,\n",
    "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.91313677e-03,\n",
    "       0.00000000e+00, 1.00748261e-01, 0.00000000e+00, 1.08247742e-30,\n",
    "       0.00000000e+00, 2.85398340e-03, 3.27684723e-02, 0.00000000e+00,\n",
    "       1.67763480e-02, 1.77694648e-37, 1.59621089e-02, 2.43698510e-03,\n",
    "       1.82430064e-02, 1.76968482e-03, 6.17823803e-03, 2.58581157e-03,\n",
    "       1.69076466e-22, 1.72313530e-03, 0.00000000e+00, 1.09488841e-02,\n",
    "       0.00000000e+00, 0.00000000e+00, 4.58267873e-02, 7.41961759e-04,\n",
    "       1.50968560e-04, 3.01750408e-31, 1.72313530e-03, 0.00000000e+00,\n",
    "       1.98422642e-37, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "       2.67792781e-37, 2.97739694e-03, 0.00000000e+00, 1.74597819e-02,\n",
    "       0.00000000e+00, 0.00000000e+00, 9.32287397e-38, 8.99111839e-01,\n",
    "       1.08085553e-21, 1.77248765e-31, 0.00000000e+00, 8.26117523e-13,\n",
    "       3.46205882e-04, 0.00000000e+00, 1.61346580e-02, 2.10348802e-03])\n",
    "\n",
    "print(stats.spearmanr(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated :\t [2.0, 2.0, 2.0, 2.0, 1.5, 1.5, 1.1666666666666667, 1.1666666666666667, 1.0, 1.0] ...\n",
      "\n",
      "Expected :\t [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8] ...\n",
      "\n",
      "\n",
      " Spearman rank correlation: \n",
      "SpearmanrResult(correlation=0.956499007414669, pvalue=3.112380269088914e-54)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clustering Coefficient \n",
    "The global clustering coefficient is the number of closed triplets (or 3 x triangles) \n",
    "over the total number of triplets (both open and closed). \n",
    "\n",
    "The local clustering coefficient is the proportion of links between the vertices \n",
    "within its neighbourhood divided by the number of links that could possibly exist between them.\n",
    "\n",
    "Average clustering coefficient is mean of local clusterings\n",
    "\"\"\"\n",
    "unsubG=nx.to_undirected(subG)\n",
    "clustering_coeffs={}\n",
    "for n in unsubG:\n",
    "    nghs = [e[1] for e in unsubG.edges(n)]\n",
    "    d=len(nghs)\n",
    "    e=subG.subgraph(nghs).number_of_edges()    \n",
    "    # for directed..\n",
    "    clustering_coeffs[n]= 1*e/(d*(d-1)) if d>1 else 0.0;\n",
    "\n",
    "compare(list(clustering_coeffs.items()),list(nx.clustering(unsubG).items()),name=\"clustering\")#,size=subSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated :\t [0.0, 0.6666666666666666, 0.7333333333333333, 0.3333333333333333, 0.31868131868131866, 2.0, 0.0, 0.6333333333333333, 2.0, 0.25] ...\n",
      "\n",
      "Expected :\t [0, 0.6666666666666666, 1.0, 0.4175824175824176, 0.358974358974359, 0, 0, 0.5, 1.0, 0.1] ...\n",
      "\n",
      "Absolute Diffs:  [0.0, 0.0, 0.2666666666666667, 0.08424908424908428, 0.040293040293040316, 2.0, 0.0, 0.1333333333333333, 1.0, 0.15] ...\n",
      "\n",
      "Sum of absolute diffs:  17.067219912395103\n",
      "\n",
      " Spearman rank correlation: \n",
      "SpearmanrResult(correlation=0.956499007414669, pvalue=3.112380269088914e-54)\n"
     ]
    }
   ],
   "source": [
    "compareDirect(list(clustering_coeffs.values()),list(nx.clustering(unsubG).values()),write=\"clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# N=3\n",
    "# G=nx.grid_2d_graph(N,N)\n",
    "# pos = dict( (n, n) for n in G.nodes() )\n",
    "# labels = dict( ((i, j), i + (N-1-j) * N ) for i, j in G.nodes() )\n",
    "# nx.relabel_nodes(G,labels,False)\n",
    "# inds=labels.keys()\n",
    "# vals=labels.values()\n",
    "# inds=sorted(inds)\n",
    "# vals=sorted(vals)\n",
    "# pos2=dict(zip(vals,inds))\n",
    "# nx.draw_networkx(G, pos=pos2, with_labels=False, node_size = 30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
